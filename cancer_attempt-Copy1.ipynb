{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51818d70-5278-452b-85f3-c395d83a4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38f7c7c-80f1-4e62-ae7c-778e65bcfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9b90b5-5698-44f1-86cf-73e6833da402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] What is the pre-metastatic niche concept? [/INST] [OUTPUT] The pre-metastatic niche (PMN) concept refers to a specific area within an organ or tissue where cancer cells can initially settle and establish themselves before spreading to other parts of the body. This concept was first proposed by researchers in 2015 as part of their efforts to better understand how metastasis occurs.\n",
      "\n",
      "The PMN is characterized by its unique cellular composition, including higher levels of extracellular matrix proteins and altered gene expression patterns compared to normal surrounding tissues. These changes make it easier for cancer cells to survive and proliferate in this environment, increasing the likelihood that they will eventually spread to distant sites throughout the body.\n",
      "\n",
      "Understanding the PMN has been crucial in developing\n"
     ]
    }
   ],
   "source": [
    "model.eval() # model in evaluation mode (dropout modules are deactivated)\n",
    "\n",
    "# craft prompt\n",
    "comment = \"What is the pre-metastatic niche concept?\"\n",
    "prompt=f'''[INST] {comment} [/INST]'''\n",
    "\n",
    "# tokenize input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# generate output\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=140)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "febaa407-9519-4f69-84b4-cd7183bf3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare the model for QLoRA fine-tuning\n",
    "model = prepare_model_for_kbit_training(model)  # Prepares the model for LoRA fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b783c43a-9326-4275-bec0-711a47a2b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SEQ_CLS', 'SEQ_2_SEQ_LM', 'CAUSAL_LM', 'TOKEN_CLS', 'QUESTION_ANS', 'FEATURE_EXTRACTION'])\n"
     ]
    }
   ],
   "source": [
    "#confirming potential task types\n",
    "from peft.mapping import MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n",
    "print(MODEL_TYPE_TO_PEFT_MODEL_MAPPING.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8afdd45-24ac-4852-bfe1-173673bce30c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.embed_tokens\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.self_attn\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.self_attn.rotary_emb\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.0.mlp.act_fn\n",
      "model.layers.0.input_layernorm\n",
      "model.layers.0.post_attention_layernorm\n",
      "model.layers.1\n",
      "model.layers.1.self_attn\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.self_attn.rotary_emb\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.1.mlp.act_fn\n",
      "model.layers.1.input_layernorm\n",
      "model.layers.1.post_attention_layernorm\n",
      "model.layers.2\n",
      "model.layers.2.self_attn\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.self_attn.rotary_emb\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.2.mlp.act_fn\n",
      "model.layers.2.input_layernorm\n",
      "model.layers.2.post_attention_layernorm\n",
      "model.layers.3\n",
      "model.layers.3.self_attn\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.self_attn.rotary_emb\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.3.mlp.act_fn\n",
      "model.layers.3.input_layernorm\n",
      "model.layers.3.post_attention_layernorm\n",
      "model.layers.4\n",
      "model.layers.4.self_attn\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.self_attn.rotary_emb\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.4.mlp.act_fn\n",
      "model.layers.4.input_layernorm\n",
      "model.layers.4.post_attention_layernorm\n",
      "model.layers.5\n",
      "model.layers.5.self_attn\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.self_attn.rotary_emb\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.5.mlp.act_fn\n",
      "model.layers.5.input_layernorm\n",
      "model.layers.5.post_attention_layernorm\n",
      "model.layers.6\n",
      "model.layers.6.self_attn\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.self_attn.rotary_emb\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.6.mlp.act_fn\n",
      "model.layers.6.input_layernorm\n",
      "model.layers.6.post_attention_layernorm\n",
      "model.layers.7\n",
      "model.layers.7.self_attn\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.self_attn.rotary_emb\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.7.mlp.act_fn\n",
      "model.layers.7.input_layernorm\n",
      "model.layers.7.post_attention_layernorm\n",
      "model.layers.8\n",
      "model.layers.8.self_attn\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.self_attn.rotary_emb\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.8.mlp.act_fn\n",
      "model.layers.8.input_layernorm\n",
      "model.layers.8.post_attention_layernorm\n",
      "model.layers.9\n",
      "model.layers.9.self_attn\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.self_attn.rotary_emb\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.9.mlp.act_fn\n",
      "model.layers.9.input_layernorm\n",
      "model.layers.9.post_attention_layernorm\n",
      "model.layers.10\n",
      "model.layers.10.self_attn\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.self_attn.rotary_emb\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.10.mlp.act_fn\n",
      "model.layers.10.input_layernorm\n",
      "model.layers.10.post_attention_layernorm\n",
      "model.layers.11\n",
      "model.layers.11.self_attn\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.self_attn.rotary_emb\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.11.mlp.act_fn\n",
      "model.layers.11.input_layernorm\n",
      "model.layers.11.post_attention_layernorm\n",
      "model.layers.12\n",
      "model.layers.12.self_attn\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.self_attn.rotary_emb\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.12.mlp.act_fn\n",
      "model.layers.12.input_layernorm\n",
      "model.layers.12.post_attention_layernorm\n",
      "model.layers.13\n",
      "model.layers.13.self_attn\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.self_attn.rotary_emb\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.13.mlp.act_fn\n",
      "model.layers.13.input_layernorm\n",
      "model.layers.13.post_attention_layernorm\n",
      "model.layers.14\n",
      "model.layers.14.self_attn\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.self_attn.rotary_emb\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.14.mlp.act_fn\n",
      "model.layers.14.input_layernorm\n",
      "model.layers.14.post_attention_layernorm\n",
      "model.layers.15\n",
      "model.layers.15.self_attn\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.self_attn.rotary_emb\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.15.mlp.act_fn\n",
      "model.layers.15.input_layernorm\n",
      "model.layers.15.post_attention_layernorm\n",
      "model.layers.16\n",
      "model.layers.16.self_attn\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.self_attn.rotary_emb\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.16.mlp.act_fn\n",
      "model.layers.16.input_layernorm\n",
      "model.layers.16.post_attention_layernorm\n",
      "model.layers.17\n",
      "model.layers.17.self_attn\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.self_attn.rotary_emb\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.17.mlp.act_fn\n",
      "model.layers.17.input_layernorm\n",
      "model.layers.17.post_attention_layernorm\n",
      "model.layers.18\n",
      "model.layers.18.self_attn\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.self_attn.rotary_emb\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.18.mlp.act_fn\n",
      "model.layers.18.input_layernorm\n",
      "model.layers.18.post_attention_layernorm\n",
      "model.layers.19\n",
      "model.layers.19.self_attn\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.self_attn.rotary_emb\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.19.mlp.act_fn\n",
      "model.layers.19.input_layernorm\n",
      "model.layers.19.post_attention_layernorm\n",
      "model.layers.20\n",
      "model.layers.20.self_attn\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.self_attn.rotary_emb\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.20.mlp.act_fn\n",
      "model.layers.20.input_layernorm\n",
      "model.layers.20.post_attention_layernorm\n",
      "model.layers.21\n",
      "model.layers.21.self_attn\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.self_attn.rotary_emb\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.21.mlp.act_fn\n",
      "model.layers.21.input_layernorm\n",
      "model.layers.21.post_attention_layernorm\n",
      "model.layers.22\n",
      "model.layers.22.self_attn\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.self_attn.rotary_emb\n",
      "model.layers.22.mlp\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.22.mlp.act_fn\n",
      "model.layers.22.input_layernorm\n",
      "model.layers.22.post_attention_layernorm\n",
      "model.layers.23\n",
      "model.layers.23.self_attn\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.self_attn.rotary_emb\n",
      "model.layers.23.mlp\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.23.mlp.act_fn\n",
      "model.layers.23.input_layernorm\n",
      "model.layers.23.post_attention_layernorm\n",
      "model.layers.24\n",
      "model.layers.24.self_attn\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.self_attn.rotary_emb\n",
      "model.layers.24.mlp\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.24.mlp.act_fn\n",
      "model.layers.24.input_layernorm\n",
      "model.layers.24.post_attention_layernorm\n",
      "model.layers.25\n",
      "model.layers.25.self_attn\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.self_attn.rotary_emb\n",
      "model.layers.25.mlp\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.25.mlp.act_fn\n",
      "model.layers.25.input_layernorm\n",
      "model.layers.25.post_attention_layernorm\n",
      "model.layers.26\n",
      "model.layers.26.self_attn\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.self_attn.rotary_emb\n",
      "model.layers.26.mlp\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.26.mlp.act_fn\n",
      "model.layers.26.input_layernorm\n",
      "model.layers.26.post_attention_layernorm\n",
      "model.layers.27\n",
      "model.layers.27.self_attn\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.self_attn.rotary_emb\n",
      "model.layers.27.mlp\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.27.mlp.act_fn\n",
      "model.layers.27.input_layernorm\n",
      "model.layers.27.post_attention_layernorm\n",
      "model.norm\n",
      "model.rotary_emb\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "#identifying potential modules for use in Lora configuration\n",
    "for name, module in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14cbde52-978d-47cf-b2af-8e39f0bc2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # LoRA rank\n",
    "    lora_alpha=32,  # Scaling factor\n",
    "    target_modules=[\"self_attn.q_proj\", \"self_attn.k_proj\", \"self_attn.v_proj\"],  # Attention layers\n",
    "    lora_dropout=0.1,  # Dropout for LoRA layers\n",
    "    bias=\"none\",  # No bias adjustment\n",
    "    task_type=\"CAUSAL_LM\"  # Task type is causal language modeling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f19a46e-4728-4de3-b169-55a6d9623c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca331c2-8f06-48d5-9a4d-771d65dffd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the datasets\n",
    "# Load question-answer pairs\n",
    "import json\n",
    "with open(\"cancer_qa.txt\", \"r\") as f:\n",
    "    qa_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ee1c91-c2c9-4c37-9b23-ce843aadc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset  # Import Dataset from the datasets library\n",
    "\n",
    "# Create a Dataset object from the question-answer pairs\n",
    "qa_dataset = Dataset.from_dict({\n",
    "    \"prompt\": [item[\"question\"] for item in qa_data],\n",
    "    \"response\": [item[\"answer\"] for item in qa_data]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5091cdd0-9abb-486c-9e35-976b9637122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unstructured course notes and create prompts\n",
    "with open(\"cancer_data.txt\", \"r\") as f:\n",
    "    course_notes = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873cc664-fb78-4740-b98a-188f8acbce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine course notes into prompt-response pairs (synthetic data generation)\n",
    "unstructured_data = [\n",
    "    {\"prompt\": f\"Explain: {note.strip()}\", \"response\": note.strip()} for note in course_notes\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3a2169-3c99-46c1-add7-169350c42928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the datasets\n",
    "all_data = Dataset.from_dict({\n",
    "    \"prompt\": qa_dataset[\"prompt\"] + [item[\"prompt\"] for item in unstructured_data],\n",
    "    \"response\": qa_dataset[\"response\"] + [item[\"response\"] for item in unstructured_data],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7b10d3-c2aa-465b-9786-1e2cf905ae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fb1dcfb89c47c69e8bf3aeb08c68ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the tokenize function\n",
    "def tokenize_function(example):\n",
    "    combined_texts = [p + \" \" + r for p, r in zip(example[\"prompt\"], example[\"response\"])]\n",
    "    return tokenizer(\n",
    "        combined_texts,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = all_data.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d31ca5b-1c7e-4f9a-a6cd-a777312a0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define training arguments\n",
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen2.5-c-tuned\",  # Directory to save the fine-tuned model\n",
    "    per_device_train_batch_size=1,  # Batch size for CPU\n",
    "    num_train_epochs=3,  # Number of training epochs\n",
    "    save_strategy=\"steps\",  # Save checkpoint after a certain number of steps\n",
    "    save_steps=500,  # Save the model every 500 steps\n",
    "    logging_dir=\"./logs\",  # Directory for logs\n",
    "    logging_steps=10,  # Log every 10 steps\n",
    "    eval_strategy=\"no\",  # No evaluation during training\n",
    "    fp16=False,  # Disable mixed-precision\n",
    "    push_to_hub=False  # Do not push to Hugging Face Hub\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ef7fdb-003e-4aec-92c3-c96a342c534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\mfaison\\AppData\\Local\\Temp\\1\\ipykernel_3040\\1975914611.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      5\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m      6\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset,\n\u001b[0;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2520\u001b[0m )\n\u001b[0;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2528\u001b[0m ):\n\u001b[0;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3653\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_accepts_loss_kwargs:\n\u001b[1;32m-> 3653\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3655\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, num_items_in_batch\u001b[38;5;241m=\u001b[39mnum_items_in_batch)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3730\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m-> 3730\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3731\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3732\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3733\u001b[0m         )\n\u001b[0;32m   3734\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   3735\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "# Step 5: Train the model\n",
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f80e900-2dbc-444a-81f2-741bbc7e6708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1cf2be4c5745f299936a9e392e25a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize and preprocess the dataset\n",
    "def preprocess_function(examples):\n",
    "    # Concatenate prompt and response element-wise\n",
    "    combined_texts = [p + \" \" + r for p, r in zip(examples[\"prompt\"], examples[\"response\"])]\n",
    "    # Tokenize the concatenated texts\n",
    "    inputs = tokenizer(combined_texts, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()  # Set input_ids as labels\n",
    "    return inputs\n",
    "\n",
    "# Apply the preprocessing to the dataset\n",
    "tokenized_dataset = all_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f8ca6d8-5fe5-4692-9554-fee70138b7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\mfaison\\AppData\\Local\\Temp\\1\\ipykernel_3040\\1893983307.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='249' max='249' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [249/249 2:03:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.545300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.535300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.607800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.554500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.346300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.198800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.343400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.204900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.135800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=249, training_loss=1.2162665707998008, metrics={'train_runtime': 7465.7666, 'train_samples_per_second': 0.033, 'train_steps_per_second': 0.033, 'total_flos': 1004597150220288.0, 'train_loss': 1.2162665707998008, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,  # The model to train\n",
    "    args=training_args,  # Training arguments\n",
    "    train_dataset=tokenized_dataset,  # The tokenized dataset\n",
    "    tokenizer=tokenizer  # Tokenizer for preprocessing\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f61846f0-6c9a-4b69-b4e3-53d311ab391e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qwen2.5-c-tuned\\\\tokenizer_config.json',\n",
       " './qwen2.5-c-tuned\\\\special_tokens_map.json',\n",
       " './qwen2.5-c-tuned\\\\vocab.json',\n",
       " './qwen2.5-c-tuned\\\\merges.txt',\n",
       " './qwen2.5-c-tuned\\\\added_tokens.json',\n",
       " './qwen2.5-c-tuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./qwen2.5-c-tuned\")  # Save the model\n",
    "tokenizer.save_pretrained(\"./qwen2.5-c-tuned\")  # Save the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4847660e-9071-4df8-b148-973d9aad9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "fine_tuned_model_dir = \"./qwen2.5-c-tuned\"\n",
    "model = AutoModelForCausalLM.from_pretrained(fine_tuned_model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(fine_tuned_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "145eea46-c2fc-4845-8243-896c3684dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] What is the pre-metastatic niche concept? [/INST] [INST] Could you please explain further? [/INST]\n"
     ]
    }
   ],
   "source": [
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define comment and create prompt\n",
    "comment = \"What is the pre-metastatic niche concept?\"\n",
    "prompt = f'''[INST] {comment} [/INST]'''\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)  # Move inputs to the correct device\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    max_new_tokens=140,\n",
    "    pad_token_id=tokenizer.pad_token_id  # Avoid warnings for missing pad token\n",
    ")\n",
    "\n",
    "# Decode and print the output\n",
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ee67412-6fef-44be-9bea-543d358ee18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the pre-metastatic niche concept? The pre-metastatic niche concept refers to a specific region within an organ or tissue that is primed and ready for metastasis, which is the spread of cancer cells from their primary site to other parts of the body. This concept was first proposed by researchers in the 1980s and has since been widely accepted as a key factor in understanding how cancer spreads.\n",
      "\n",
      "The pre-metastatic niche concept suggests that certain environmental cues, such as inflammation, immune cell infiltration, and changes in blood flow, can create a favorable microenvironment within the primary tumor that promotes the survival and proliferation of cancer cells. These cancer cells then secrete growth factors and cytokines that further promote their\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "comment = \"What is the pre-metastatic niche concept?\"\n",
    "prompt = f\"{comment}\"  # Simplified prompt without [INST] tags\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],  # Explicit attention mask\n",
    "    max_new_tokens=140,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "460c771f-777c-4d72-bb76-b94482dd932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': 'Explain: Section 1: Tumor Microenvironment (TME)', 'response': 'Section 1: Tumor Microenvironment (TME)'}, {'prompt': 'Explain: Definition and Importance', 'response': 'Definition and Importance'}, {'prompt': 'Explain: The tumor microenvironment (TME) refers to the ecosystem surrounding cancer cells, which includes non-cancerous cells, blood vessels, immune cells, fibroblasts, extracellular matrix (ECM), and signaling molecules. The TME plays a critical role in all stages of cancer development, from onset to metastasis.', 'response': 'The tumor microenvironment (TME) refers to the ecosystem surrounding cancer cells, which includes non-cancerous cells, blood vessels, immune cells, fibroblasts, extracellular matrix (ECM), and signaling molecules. The TME plays a critical role in all stages of cancer development, from onset to metastasis.'}, {'prompt': 'Explain: Components of the TME', 'response': 'Components of the TME'}, {'prompt': 'Explain: 1. Blood Vessels: Provide nutrients and oxygen through angiogenesis.', 'response': '1. Blood Vessels: Provide nutrients and oxygen through angiogenesis.'}, {'prompt': 'Explain: 2. Immune Cells: Interact with tumors, sometimes supporting cancer growth by suppressing anti-tumor responses.', 'response': '2. Immune Cells: Interact with tumors, sometimes supporting cancer growth by suppressing anti-tumor responses.'}, {'prompt': 'Explain: 3. Fibroblasts and ECM: Offer structural support and pathways for cell migration.', 'response': '3. Fibroblasts and ECM: Offer structural support and pathways for cell migration.'}, {'prompt': 'Explain: 4. Signaling Molecules: Mediate communication between cancer cells and the surrounding environment.', 'response': '4. Signaling Molecules: Mediate communication between cancer cells and the surrounding environment.'}, {'prompt': 'Explain: Key Concepts', 'response': 'Key Concepts'}, {'prompt': 'Explain: * Seed and Soil Hypothesis: Cancer cells (seeds) thrive only in conducive environments (soil).', 'response': '* Seed and Soil Hypothesis: Cancer cells (seeds) thrive only in conducive environments (soil).'}, {'prompt': 'Explain: * Integrins and CAMs: Mediate adhesion between cells and ECM, promoting tumor survival and progression.', 'response': '* Integrins and CAMs: Mediate adhesion between cells and ECM, promoting tumor survival and progression.'}, {'prompt': 'Explain: ', 'response': ''}, {'prompt': 'Explain: Section 2: Metastasis', 'response': 'Section 2: Metastasis'}, {'prompt': 'Explain: Definition', 'response': 'Definition'}, {'prompt': 'Explain: Metastasis is the process by which cancer cells spread from the primary tumor to distant sites, forming secondary tumors. This is the leading cause of cancer-related deaths.', 'response': 'Metastasis is the process by which cancer cells spread from the primary tumor to distant sites, forming secondary tumors. This is the leading cause of cancer-related deaths.'}, {'prompt': 'Explain: Steps of Metastasis', 'response': 'Steps of Metastasis'}, {'prompt': 'Explain: 1. Invasion: Cancer cells penetrate the ECM and surrounding tissues.', 'response': '1. Invasion: Cancer cells penetrate the ECM and surrounding tissues.'}, {'prompt': 'Explain: 2. Intravasation: Cells enter blood or lymphatic vessels.', 'response': '2. Intravasation: Cells enter blood or lymphatic vessels.'}, {'prompt': 'Explain: 3. Survival in Circulation: Cells evade immune cells and shear stress in the bloodstream.', 'response': '3. Survival in Circulation: Cells evade immune cells and shear stress in the bloodstream.'}, {'prompt': 'Explain: 4. Extravasation: Cells exit vessels and invade new tissues.', 'response': '4. Extravasation: Cells exit vessels and invade new tissues.'}, {'prompt': 'Explain: 5. Colonization: Cells establish and grow in a new microenvironment.', 'response': '5. Colonization: Cells establish and grow in a new microenvironment.'}, {'prompt': 'Explain: Key Mechanisms', 'response': 'Key Mechanisms'}, {'prompt': 'Explain: * Epithelial-Mesenchymal Transition (EMT): Cancer cells lose adhesion and gain motility by altering integrins and downregulating E-cadherin.', 'response': '* Epithelial-Mesenchymal Transition (EMT): Cancer cells lose adhesion and gain motility by altering integrins and downregulating E-cadherin.'}, {'prompt': 'Explain: * Pre-Metastatic Niche: Primary tumors send signals to prepare distant tissues for colonization.', 'response': '* Pre-Metastatic Niche: Primary tumors send signals to prepare distant tissues for colonization.'}, {'prompt': 'Explain: ', 'response': ''}, {'prompt': 'Explain: Section 3: Cell Death Mechanisms', 'response': 'Section 3: Cell Death Mechanisms'}, {'prompt': 'Explain: Overview', 'response': 'Overview'}, {'prompt': 'Explain: Cell death mechanisms regulate cell survival and homeostasis. Cancer cells often evade these mechanisms to proliferate uncontrollably.', 'response': 'Cell death mechanisms regulate cell survival and homeostasis. Cancer cells often evade these mechanisms to proliferate uncontrollably.'}, {'prompt': 'Explain: Types of Cell Death', 'response': 'Types of Cell Death'}, {'prompt': 'Explain: 1. Apoptosis (Programmed Cell Death):', 'response': '1. Apoptosis (Programmed Cell Death):'}, {'prompt': 'Explain: o Controlled process involving caspase activation.', 'response': 'o Controlled process involving caspase activation.'}, {'prompt': 'Explain: o Prevents inflammation and plays a key role in tumor suppression.', 'response': 'o Prevents inflammation and plays a key role in tumor suppression.'}, {'prompt': 'Explain: o Cancer cells evade apoptosis through mutations in genes like TP53.', 'response': 'o Cancer cells evade apoptosis through mutations in genes like TP53.'}, {'prompt': 'Explain: 2. Necrosis (Unplanned Cell Death):', 'response': '2. Necrosis (Unplanned Cell Death):'}, {'prompt': 'Explain: o Causes inflammation due to the release of cellular contents.', 'response': 'o Causes inflammation due to the release of cellular contents.'}, {'prompt': 'Explain: o May promote cancer progression by attracting immune cells and stimulating angiogenesis.', 'response': 'o May promote cancer progression by attracting immune cells and stimulating angiogenesis.'}, {'prompt': 'Explain: 3. Autophagy (Self-Degradative Process):', 'response': '3. Autophagy (Self-Degradative Process):'}, {'prompt': 'Explain: o A survival mechanism under stress conditions.', 'response': 'o A survival mechanism under stress conditions.'}, {'prompt': 'Explain: o Excessive autophagy can lead to cell death, but in cancer, it may help cells survive adverse conditions like hypoxia or nutrient deprivation.', 'response': 'o Excessive autophagy can lead to cell death, but in cancer, it may help cells survive adverse conditions like hypoxia or nutrient deprivation.'}, {'prompt': 'Explain: ', 'response': ''}, {'prompt': 'Explain: Section 4: Environmental Carcinogenesis', 'response': 'Section 4: Environmental Carcinogenesis'}, {'prompt': 'Explain: Definition', 'response': 'Definition'}, {'prompt': 'Explain: Environmental carcinogenesis refers to cancer development caused by exposure to external carcinogens such as chemicals, radiation, and lifestyle factors.', 'response': 'Environmental carcinogenesis refers to cancer development caused by exposure to external carcinogens such as chemicals, radiation, and lifestyle factors.'}, {'prompt': 'Explain: Major Environmental Factors', 'response': 'Major Environmental Factors'}, {'prompt': 'Explain: 1. Tobacco Smoke:', 'response': '1. Tobacco Smoke:'}, {'prompt': 'Explain: o Contains over 50 known carcinogens (e.g., benzo[a]pyrene, nitrosamines).', 'response': 'o Contains over 50 known carcinogens (e.g., benzo[a]pyrene, nitrosamines).'}, {'prompt': 'Explain: o Responsible for approximately 30% of all cancer deaths, particularly lung cancer.', 'response': 'o Responsible for approximately 30% of all cancer deaths, particularly lung cancer.'}, {'prompt': 'Explain: 2. Diet and Obesity:', 'response': '2. Diet and Obesity:'}, {'prompt': 'Explain: o High consumption of red/processed meats increases colorectal cancer risk.', 'response': 'o High consumption of red/processed meats increases colorectal cancer risk.'}, {'prompt': 'Explain: o Obesity promotes hormone-driven cancers due to chronic inflammation and altered insulin signaling.', 'response': 'o Obesity promotes hormone-driven cancers due to chronic inflammation and altered insulin signaling.'}, {'prompt': 'Explain: 3. Radiation:', 'response': '3. Radiation:'}, {'prompt': 'Explain: o Ultraviolet (UV) radiation causes skin cancers by inducing DNA mutations.', 'response': 'o Ultraviolet (UV) radiation causes skin cancers by inducing DNA mutations.'}, {'prompt': 'Explain: o Ionizing radiation from medical imaging or environmental exposure is linked to multiple cancers.', 'response': 'o Ionizing radiation from medical imaging or environmental exposure is linked to multiple cancers.'}, {'prompt': 'Explain: 4. Chemical Exposures:', 'response': '4. Chemical Exposures:'}, {'prompt': 'Explain: o Occupational carcinogens (e.g., asbestos, benzene) have been linked to lung, liver, and bladder cancers.', 'response': 'o Occupational carcinogens (e.g., asbestos, benzene) have been linked to lung, liver, and bladder cancers.'}, {'prompt': 'Explain: o Pesticides and industrial chemicals like vinyl chloride are associated with various malignancies.', 'response': 'o Pesticides and industrial chemicals like vinyl chloride are associated with various malignancies.'}, {'prompt': 'Explain: 5. Infections:', 'response': '5. Infections:'}, {'prompt': 'Explain: o Viruses such as HPV, HBV, and H. pylori contribute to cervical, liver, and stomach cancers, respectively.', 'response': 'o Viruses such as HPV, HBV, and H. pylori contribute to cervical, liver, and stomach cancers, respectively.'}, {'prompt': 'Explain: Mechanisms of Action', 'response': 'Mechanisms of Action'}, {'prompt': 'Explain: * Carcinogens induce DNA damage, oxidative stress, or inflammation, leading to mutations and disruptions in normal cell function.', 'response': '* Carcinogens induce DNA damage, oxidative stress, or inflammation, leading to mutations and disruptions in normal cell function.'}, {'prompt': 'Explain: * Genetic susceptibility can influence individual risk, highlighting the importance of gene-environment interactions.', 'response': '* Genetic susceptibility can influence individual risk, highlighting the importance of gene-environment interactions.'}, {'prompt': 'Explain: ', 'response': ''}, {'prompt': 'Explain: Key Integrative Concepts', 'response': 'Key Integrative Concepts'}, {'prompt': 'Explain: TME and Metastasis', 'response': 'TME and Metastasis'}, {'prompt': 'Explain: * Integrins and CAMs are crucial for both TME dynamics and the metastatic process. By facilitating adhesion, migration, and signaling, these molecules enable cancer cells to interact with their environment and thrive in new locations.', 'response': '* Integrins and CAMs are crucial for both TME dynamics and the metastatic process. By facilitating adhesion, migration, and signaling, these molecules enable cancer cells to interact with their environment and thrive in new locations.'}, {'prompt': 'Explain: Cell Death and Therapy', 'response': 'Cell Death and Therapy'}, {'prompt': 'Explain: * Understanding how cancer evades apoptosis and exploits necrosis or autophagy opens doors for targeted therapies that restore normal cell death processes.', 'response': '* Understanding how cancer evades apoptosis and exploits necrosis or autophagy opens doors for targeted therapies that restore normal cell death processes.'}, {'prompt': 'Explain: Environmental and Lifestyle Interventions', 'response': 'Environmental and Lifestyle Interventions'}, {'prompt': 'Explain: * Reducing exposure to known carcinogens and promoting healthy behaviors, such as smoking cessation and a balanced diet, are key strategies for cancer prevention.', 'response': '* Reducing exposure to known carcinogens and promoting healthy behaviors, such as smoking cessation and a balanced diet, are key strategies for cancer prevention.'}, {'prompt': 'Explain: ', 'response': ''}, {'prompt': 'Explain: Conclusion', 'response': 'Conclusion'}, {'prompt': 'Explain: The interplay between the tumor microenvironment, cell death mechanisms, metastasis, and environmental factors provides a comprehensive framework for understanding cancer biology. Targeting these interconnected processes offers promising avenues for prevention, diagnosis, and treatment.', 'response': 'The interplay between the tumor microenvironment, cell death mechanisms, metastasis, and environmental factors provides a comprehensive framework for understanding cancer biology. Targeting these interconnected processes offers promising avenues for prevention, diagnosis, and treatment.'}, {'prompt': 'Explain: ', 'response': ''}]\n"
     ]
    }
   ],
   "source": [
    "print(unstructured_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
